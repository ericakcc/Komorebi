"""Project management tools for Komorebi.

å­¸ç¿’é‡é»žï¼š
- @tool decorator å®šç¾©å·¥å…·çš„ä¸‰å€‹åƒæ•¸ï¼šname, description, input_schema
- å·¥å…·å‡½æ•¸å¿…é ˆæ˜¯ async def
- å›žå‚³æ ¼å¼ï¼š{"content": [{"type": "text", "text": "..."}]}
- éŒ¯èª¤æ™‚åŠ ä¸Š "is_error": True
- ä½¿ç”¨ Pydantic BaseModel é©—è­‰å·¥å…·è¼¸å…¥

é€™äº›å·¥å…·ç”¨æ–¼è®€å¯« data/projects/*.md æª”æ¡ˆã€‚
"""

import asyncio
import logging
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

import frontmatter
from claude_agent_sdk import ClaudeAgentOptions, query, tool
from claude_agent_sdk.types import ResultMessage
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# ============================================================================
# Pydantic Input Models
# ============================================================================


class ProjectStatus(str, Enum):
    """Valid project statuses."""

    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    ARCHIVED = "archived"


class ShowProjectInput(BaseModel):
    """Input schema for show_project tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")


class UpdateStatusInput(BaseModel):
    """Input schema for update_project_status tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    status: ProjectStatus = Field(..., description="æ–°ç‹€æ…‹")


class UpdateProgressInput(BaseModel):
    """Input schema for update_project_progress tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    days: int = Field(default=1, ge=1, le=30, description="åˆ†æžæœ€è¿‘å¹¾å¤©çš„è®Šæ›´")


class SyncProjectInput(BaseModel):
    """Input schema for sync_project tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    force: bool = Field(default=False, description="æ˜¯å¦å¼·åˆ¶è¦†å¯«")


# å°ˆæ¡ˆè³‡æ–™ç›®éŒ„ï¼Œç”± agent è¨­å®š
_data_dir: Path = Path("data")


def set_data_dir(path: Path) -> None:
    """Set the data directory for project tools.

    Args:
        path: Path to the data directory containing projects/.
    """
    global _data_dir
    _data_dir = path


def _get_projects_dir() -> Path:
    """Get the projects directory path."""
    return _data_dir / "projects"


@tool(
    name="list_projects",
    description="åˆ—å‡ºæ‰€æœ‰å°ˆæ¡ˆåŠå…¶ç‹€æ…‹ã€‚å›žå‚³å°ˆæ¡ˆåç¨±ã€ç‹€æ…‹ã€å„ªå…ˆé †åºç­‰æ‘˜è¦è³‡è¨Šã€‚",
    input_schema={},  # ç„¡åƒæ•¸
)
async def list_projects(args: dict[str, Any]) -> dict[str, Any]:
    """List all projects from data/projects/*.md files.

    è®€å–æ¯å€‹ markdown æª”æ¡ˆçš„ frontmatter ä¾†å–å¾—å°ˆæ¡ˆè³‡è¨Šã€‚

    Returns:
        Tool response with formatted project list.
    """
    projects_dir = _get_projects_dir()

    if not projects_dir.exists():
        return {
            "content": [
                {"type": "text", "text": "å°ˆæ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨ã€‚è«‹å…ˆå»ºç«‹ data/projects/ ç›®éŒ„ã€‚"}
            ],
            "is_error": True,
        }

    projects: list[dict[str, Any]] = []

    for md_file in projects_dir.glob("*.md"):
        try:
            post = frontmatter.load(md_file)
            projects.append(
                {
                    "name": post.get("name", md_file.stem),
                    "status": post.get("status", "unknown"),
                    "priority": post.get("priority", 999),
                    "file": md_file.name,
                }
            )
        except (OSError, IOError) as e:
            logger.warning(f"Failed to read {md_file}: {e}")
            projects.append(
                {
                    "name": md_file.stem,
                    "status": "error: file read failed",
                    "priority": 999,
                    "file": md_file.name,
                }
            )
        except (KeyError, ValueError) as e:
            logger.warning(f"Failed to parse frontmatter in {md_file}: {e}")
            projects.append(
                {
                    "name": md_file.stem,
                    "status": "error: invalid format",
                    "priority": 999,
                    "file": md_file.name,
                }
            )

    if not projects:
        return {
            "content": [{"type": "text", "text": "ç›®å‰æ²’æœ‰ä»»ä½•å°ˆæ¡ˆã€‚"}],
        }

    # æŒ‰å„ªå…ˆé †åºæŽ’åº
    projects.sort(key=lambda p: p["priority"])

    # æ ¼å¼åŒ–è¼¸å‡º
    lines = ["## å°ˆæ¡ˆåˆ—è¡¨\n"]
    for p in projects:
        status_emoji = {
            "active": "ðŸŸ¢",
            "paused": "â¸ï¸",
            "completed": "âœ…",
            "archived": "ðŸ“¦",
        }.get(p["status"], "â“")

        lines.append(f"- {status_emoji} **{p['name']}** ({p['status']})")

    return {
        "content": [{"type": "text", "text": "\n".join(lines)}],
    }


@tool(
    name="show_project",
    description="é¡¯ç¤ºå–®ä¸€å°ˆæ¡ˆçš„å®Œæ•´è³‡è¨Šï¼ŒåŒ…å«ç›®æ¨™ã€æŠ€è¡“æ£§ã€é€²åº¦ã€blockers ç­‰è©³ç´°å…§å®¹ã€‚",
    input_schema=ShowProjectInput.model_json_schema(),
)
async def show_project(args: dict[str, Any]) -> dict[str, Any]:
    """Show detailed information about a specific project.

    è®€å–ä¸¦å›žå‚³å®Œæ•´çš„å°ˆæ¡ˆ markdown æª”æ¡ˆå…§å®¹ã€‚

    Args:
        args: Dictionary containing 'name' - the project name (case-insensitive).

    Returns:
        Tool response with project details.
    """
    try:
        validated = ShowProjectInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name

    projects_dir = _get_projects_dir()

    # å˜—è©¦æ‰¾åˆ°åŒ¹é…çš„æª”æ¡ˆï¼ˆä¸åˆ†å¤§å°å¯«ï¼‰
    project_file = None
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() == name.lower():
            project_file = md_file
            break

    if not project_file or not project_file.exists():
        # åˆ—å‡ºå¯ç”¨çš„å°ˆæ¡ˆ
        available = [f.stem for f in projects_dir.glob("*.md")]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    content = project_file.read_text(encoding="utf-8")
    return {
        "content": [{"type": "text", "text": content}],
    }


@tool(
    name="update_project_status",
    description="æ›´æ–°å°ˆæ¡ˆçš„ç‹€æ…‹ï¼ˆactive, paused, completed, archivedï¼‰ã€‚",
    input_schema=UpdateStatusInput.model_json_schema(),
)
async def update_project_status(args: dict[str, Any]) -> dict[str, Any]:
    """Update the status of a project.

    ä¿®æ”¹å°ˆæ¡ˆ markdown æª”æ¡ˆçš„ frontmatter ä¸­çš„ status æ¬„ä½ã€‚

    Args:
        args: Dictionary containing 'name' and 'status'.

    Returns:
        Tool response confirming the update.
    """
    try:
        validated = UpdateStatusInput(**args)
    except ValueError as e:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}\næœ‰æ•ˆç‹€æ…‹ï¼šactive, paused, completed, archived",
                }
            ],
            "is_error": True,
        }

    name = validated.name
    new_status = validated.status.value

    projects_dir = _get_projects_dir()

    # æ‰¾åˆ°æª”æ¡ˆ
    project_file = None
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() == name.lower():
            project_file = md_file
            break

    if not project_file or not project_file.exists():
        return {
            "content": [{"type": "text", "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}"}],
            "is_error": True,
        }

    # è®€å–ä¸¦æ›´æ–°
    try:
        post = frontmatter.load(project_file)
        old_status = post.get("status", "unknown")
        post["status"] = new_status

        project_file.write_text(frontmatter.dumps(post), encoding="utf-8")

        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å·²æ›´æ–° **{name}** ç‹€æ…‹ï¼š{old_status} â†’ {new_status}",
                }
            ],
        }
    except (OSError, IOError) as e:
        logger.error(f"Failed to write project file {project_file}: {e}")
        return {
            "content": [{"type": "text", "text": f"å¯«å…¥æª”æ¡ˆå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }
    except (KeyError, ValueError) as e:
        logger.error(f"Failed to parse frontmatter in {project_file}: {e}")
        return {
            "content": [{"type": "text", "text": f"æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼š{e}"}],
            "is_error": True,
        }


# ============================================================================
# Progress Analysis Tool
# ============================================================================


async def _run_git_command(repo_path: Path, args: list[str]) -> str:
    """Run a git command asynchronously and return output.

    Args:
        repo_path: Path to the git repository.
        args: Git command arguments.

    Returns:
        Command output or empty string on error.
    """
    try:
        process = await asyncio.create_subprocess_exec(
            "git",
            *args,
            cwd=repo_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.DEVNULL,
        )
        stdout, _ = await asyncio.wait_for(process.communicate(), timeout=30)
        if process.returncode == 0:
            return stdout.decode().strip()
    except asyncio.TimeoutError:
        logger.warning(f"Git command timed out: git {' '.join(args)}")
    except FileNotFoundError:
        logger.warning("Git executable not found")
    except OSError as e:
        logger.warning(f"Git command failed: {e}")
    return ""


async def _collect_git_info(repo_path: Path, days: int = 1) -> dict[str, str]:
    """Collect git log and diff information asynchronously.

    Args:
        repo_path: Path to the git repository.
        days: Number of days to look back.

    Returns:
        Dictionary with log, diff, and changed_files.
    """
    # Run git commands in parallel for better performance
    log_task = _run_git_command(repo_path, ["log", f"--since={days} days ago", "--oneline"])
    diff_task = _run_git_command(repo_path, ["diff", f"HEAD~{days}", "--stat"])
    diff_content_task = _run_git_command(repo_path, ["diff", f"HEAD~{days}"])
    changed_files_task = _run_git_command(repo_path, ["diff", "--name-only", f"HEAD~{days}"])

    log, diff, diff_content, changed_files = await asyncio.gather(
        log_task, diff_task, diff_content_task, changed_files_task
    )

    return {
        "log": log,
        "diff": diff,
        "diff_content": diff_content,
        "changed_files": changed_files,
    }


async def _analyze_with_sonnet(project_name: str, git_info: dict[str, str]) -> str:
    """Use Sonnet to analyze project progress.

    Args:
        project_name: Name of the project.
        git_info: Dictionary with git information.

    Returns:
        Progress summary in Traditional Chinese.
    """
    # é™åˆ¶ diff é•·åº¦é¿å… token éŽå¤š
    diff_content = git_info["diff_content"][:4000] if git_info["diff_content"] else "(ç„¡è®Šæ›´)"

    prompt = f"""åˆ†æžä»¥ä¸‹å°ˆæ¡ˆçš„é€²åº¦ï¼Œç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ç°¡æ½”çš„é€²åº¦æ‘˜è¦ï¼ˆ3-5 å€‹ bullet pointsï¼‰ã€‚

## å°ˆæ¡ˆï¼š{project_name}

## Git Commits
{git_info["log"] or "(ç„¡ commits)"}

## æª”æ¡ˆè®Šæ›´çµ±è¨ˆ
{git_info["diff"] or "(ç„¡è®Šæ›´)"}

## ç¨‹å¼ç¢¼è®Šæ›´å…§å®¹
{diff_content}

è«‹ç›´æŽ¥è¼¸å‡ºé€²åº¦æ‘˜è¦ï¼Œä¸è¦æœ‰é–‹é ­èªžæˆ–çµå°¾èªžã€‚æ ¼å¼ï¼š
- ç¬¬ä¸€é …é€²åº¦
- ç¬¬äºŒé …é€²åº¦
..."""

    options = ClaudeAgentOptions(model="claude-sonnet-4-5-20250929")
    result_text = ""

    async for message in query(prompt=prompt, options=options):
        if isinstance(message, ResultMessage):
            # å¾ž ResultMessage ä¸­æå–æ–‡å­—
            if hasattr(message, "result") and message.result:
                result_text = message.result
                break

    return result_text


def _append_progress_log(project_file: Path, date_str: str, summary: str) -> None:
    """Append progress summary to project's progress log.

    Args:
        project_file: Path to the project markdown file.
        date_str: Date string (YYYY-MM-DD).
        summary: Progress summary to append.
    """
    post = frontmatter.load(project_file)
    content = post.content

    # æ‰¾åˆ° "## é€²åº¦æ—¥èªŒ" å€å¡Š
    if "## é€²åº¦æ—¥èªŒ" in content:
        # åœ¨ "## é€²åº¦æ—¥èªŒ" å¾Œæ’å…¥æ–°æ—¥èªŒ
        parts = content.split("## é€²åº¦æ—¥èªŒ")
        new_entry = f"\n\n### {date_str}\n{summary}"
        content = parts[0] + "## é€²åº¦æ—¥èªŒ" + new_entry + parts[1]
    else:
        # å¦‚æžœæ²’æœ‰é€²åº¦æ—¥èªŒå€å¡Šï¼Œåœ¨æœ€å¾ŒåŠ ä¸Š
        content += f"\n\n## é€²åº¦æ—¥èªŒ\n\n### {date_str}\n{summary}"

    post.content = content

    project_file.write_text(frontmatter.dumps(post), encoding="utf-8")


@tool(
    name="update_project_progress",
    description="ç”¨ AI åˆ†æžå°ˆæ¡ˆçš„ git è®Šæ›´ï¼Œè‡ªå‹•æ’°å¯«é€²åº¦æ—¥èªŒã€‚æœƒç ”ç©¶ commits å’Œç¨‹å¼ç¢¼è®Šæ›´å¾Œç”Ÿæˆæ‘˜è¦ã€‚",
    input_schema=UpdateProgressInput.model_json_schema(),
)
async def update_project_progress(args: dict[str, Any]) -> dict[str, Any]:
    """Analyze project git changes and update progress log.

    ä½¿ç”¨ Sonnet åˆ†æžå°ˆæ¡ˆçš„ git commits å’Œç¨‹å¼ç¢¼è®Šæ›´ï¼Œ
    è‡ªå‹•ç”Ÿæˆé€²åº¦æ‘˜è¦ä¸¦å¯«å…¥å°ˆæ¡ˆçš„é€²åº¦æ—¥èªŒã€‚

    Args:
        args: Dictionary containing:
            - name: å°ˆæ¡ˆåç¨±
            - days: åˆ†æžæœ€è¿‘å¹¾å¤©çš„è®Šæ›´ï¼ˆé è¨­ 1ï¼‰

    Returns:
        Tool response with generated progress summary.
    """
    try:
        validated = UpdateProgressInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name
    days = validated.days

    # æ‰¾åˆ°å°ˆæ¡ˆæª”æ¡ˆ
    projects_dir = _get_projects_dir()
    project_file = None
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() == name.lower():
            project_file = md_file
            break

    if not project_file:
        available = [f.stem for f in projects_dir.glob("*.md")]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # è®€å–å°ˆæ¡ˆçš„ repo è·¯å¾‘
    post = frontmatter.load(project_file)
    repo_path = post.get("repo", "")

    if not repo_path:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} æ²’æœ‰è¨­å®š repo è·¯å¾‘ã€‚è«‹åœ¨ frontmatter ä¸­åŠ å…¥ repo æ¬„ä½ã€‚",
                }
            ],
            "is_error": True,
        }

    # å±•é–‹è·¯å¾‘
    repo_path = Path(repo_path).expanduser()
    if not repo_path.exists():
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨ï¼š{repo_path}",
                }
            ],
            "is_error": True,
        }

    # æ”¶é›† git è³‡è¨Š
    git_info = await _collect_git_info(repo_path, days)

    if not git_info["log"]:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} åœ¨æœ€è¿‘ {days} å¤©å…§æ²’æœ‰ commitsã€‚",
                }
            ],
        }

    # ç”¨ Sonnet åˆ†æž
    try:
        summary = await _analyze_with_sonnet(name, git_info)
    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"AI åˆ†æžå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    # æ›´æ–°é€²åº¦æ—¥èªŒ
    date_str = datetime.now().strftime("%Y-%m-%d")
    _append_progress_log(project_file, date_str, summary)

    return {
        "content": [
            {
                "type": "text",
                "text": f"""## å·²æ›´æ–° {name} çš„é€²åº¦æ—¥èªŒ

**æ—¥æœŸ**: {date_str}
**åˆ†æžç¯„åœ**: æœ€è¿‘ {days} å¤©
**Commits**: {len(git_info["log"].splitlines())} ç­†

### é€²åº¦æ‘˜è¦
{summary}

å·²å¯«å…¥ {project_file}""",
            }
        ],
    }


# ============================================================================
# Project Sync Tool
# ============================================================================


def _read_file_safely(file_path: Path, max_chars: int = 4000) -> str:
    """Read file content with size limit.

    Args:
        file_path: Path to file.
        max_chars: Maximum characters to read.

    Returns:
        File content (truncated if needed) or empty string.
    """
    if not file_path.exists():
        return ""
    try:
        content = file_path.read_text(encoding="utf-8")
        if len(content) > max_chars:
            return content[:max_chars] + "\n...(truncated)"
        return content
    except Exception:
        return ""


async def _collect_repo_info_full(repo_path: Path, full_analysis: bool = False) -> dict[str, str]:
    """Collect comprehensive repository information asynchronously.

    Args:
        repo_path: Path to the repository.
        full_analysis: If True, collect more data for init mode.

    Returns:
        Dictionary with readme, claude_md, other_docs, dependencies,
        structure, git_log.
    """
    info: dict[str, str] = {}

    # README
    info["readme"] = _read_file_safely(repo_path / "README.md")

    # CLAUDE.md (if exists)
    info["claude_md"] = _read_file_safely(repo_path / "CLAUDE.md")

    # Dependencies (pyproject.toml or package.json)
    deps_file = repo_path / "pyproject.toml"
    if not deps_file.exists():
        deps_file = repo_path / "package.json"
    info["dependencies"] = _read_file_safely(deps_file, max_chars=2000)

    # Directory structure
    info["structure"] = await _run_git_command(
        repo_path,
        ["-c", "core.quotepath=false", "ls-tree", "-r", "--name-only", "HEAD"],
    )
    if not info["structure"]:
        # Fallback: use find command asynchronously
        try:
            process = await asyncio.create_subprocess_exec(
                "find",
                ".",
                "-maxdepth",
                "3",
                "-type",
                "f",
                "-name",
                "*.py",
                cwd=repo_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.DEVNULL,
            )
            stdout, _ = await asyncio.wait_for(process.communicate(), timeout=10)
            info["structure"] = stdout.decode().strip()
        except (asyncio.TimeoutError, OSError) as e:
            logger.warning(f"Failed to get directory structure: {e}")
            info["structure"] = "(ç„¡æ³•å–å¾—ç›®éŒ„çµæ§‹)"

    # Git log
    if full_analysis:
        # Full history for init mode
        info["git_log"] = await _run_git_command(repo_path, ["log", "--oneline", "-50"])
        # Other docs
        other_docs = []
        for doc_name in ["TECHNICAL.md", "API_SPEC.md", "ARCHITECTURE.md"]:
            doc_content = _read_file_safely(repo_path / doc_name, max_chars=2000)
            if doc_content:
                other_docs.append(f"### {doc_name}\n{doc_content}")
        info["other_docs"] = "\n\n".join(other_docs) if other_docs else "(ç„¡)"
    else:
        # Recent history for sync mode
        info["git_log"] = await _run_git_command(
            repo_path, ["log", "--since=7 days ago", "--oneline"]
        )
        info["other_docs"] = "(sync mode: ç•¥éŽ)"

    return info


def _is_default_content(content: str) -> bool:
    """Check if project content contains default/placeholder values.

    Args:
        content: Project markdown content.

    Returns:
        True if content appears to be default/placeholder.
    """
    default_markers = [
        "Layer-wise training framework",  # LayerWise çš„éŒ¯èª¤é è¨­æè¿°
        "å¾…å¡«å¯«",
        "TODO:",
        "(ç„¡å…§å®¹)",
        "Description here",
        "Add description",
    ]
    return any(marker.lower() in content.lower() for marker in default_markers)


INIT_PROMPT = """ä½ æ˜¯å°ˆæ¡ˆåˆ†æžåŠ©ç†ã€‚æ ¹æ“šä»¥ä¸‹ repository è³‡è¨Šï¼Œç‚ºé€™å€‹æˆç†Ÿå°ˆæ¡ˆç”Ÿæˆå®Œæ•´çš„å°ˆæ¡ˆæ–‡ä»¶ã€‚

## Repository è³‡è¨Š

### README
{readme}

### é–‹ç™¼æŒ‡å— (CLAUDE.md)
{claude_md}

### å…¶ä»–æ–‡æª”
{other_docs}

### ä¾è³´é…ç½®
{dependencies}

### ç›®éŒ„çµæ§‹
{structure}

### Git é–‹ç™¼æ­·å²
{git_log}

## è¼¸å‡ºæ ¼å¼ (YAML)

è«‹ç”¨ YAML æ ¼å¼è¼¸å‡ºä»¥ä¸‹æ¬„ä½ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚ç›´æŽ¥è¼¸å‡º YAML å…§å®¹ï¼Œä¸è¦æœ‰ ```yaml æ¨™è¨˜ï¼š

goal: |
  å°ˆæ¡ˆçš„æ ¸å¿ƒç›®æ¨™èˆ‡åƒ¹å€¼ä¸»å¼µï¼ˆ2-3 å¥ï¼‰

tech_stack:
  - "Language: Python 3.12"
  - "Framework: FastAPI"
  - "Core: pypotrace (å‘é‡ææ‘¹)"
  # åˆ—å‡ºæ‰€æœ‰é—œéµæŠ€è¡“ï¼Œé™„ä¸Šç”¨é€”èªªæ˜Ž

current_progress:
  - "[x] å·²å®Œæˆçš„åŠŸèƒ½"
  - "[ ] é€²è¡Œä¸­æˆ–å¾…è¾¦çš„åŠŸèƒ½"
  # æ ¹æ“šç¨‹å¼ç¢¼çµæ§‹å’Œ git history æŽ¨æ¸¬

blockers:
  - "(ç„¡)"
  # æˆ–æè¿°ç™¼ç¾çš„æ½›åœ¨å•é¡Œ

æ³¨æ„ï¼š
1. goal è¦ç²¾ç¢ºæè¿°å°ˆæ¡ˆç›®çš„å’Œæ ¸å¿ƒåƒ¹å€¼
2. tech_stack è¦å®Œæ•´ï¼Œæ¯é …é™„ä¸Šç”¨é€”
3. current_progress æ ¹æ“šç¨‹å¼ç¢¼çµæ§‹æŽ¨æ¸¬å®Œæˆåº¦
4. ç›´æŽ¥è¼¸å‡º YAMLï¼Œé–‹é ­æ˜¯ goal:
"""


async def _analyze_repo_for_init(
    project_name: str,
    repo_info: dict[str, str],
) -> dict[str, Any]:
    """Use Sonnet to analyze repository for init mode.

    Args:
        project_name: Name of the project.
        repo_info: Collected repository information.

    Returns:
        Parsed YAML as dictionary, or empty dict on error.
    """
    import yaml

    prompt = INIT_PROMPT.format(
        readme=repo_info.get("readme", "(ç„¡)"),
        claude_md=repo_info.get("claude_md", "(ç„¡)"),
        other_docs=repo_info.get("other_docs", "(ç„¡)"),
        dependencies=repo_info.get("dependencies", "(ç„¡)"),
        structure=repo_info.get("structure", "(ç„¡)"),
        git_log=repo_info.get("git_log", "(ç„¡)"),
    )

    options = ClaudeAgentOptions(model="claude-sonnet-4-5-20250929")
    result_text = ""

    async for message in query(prompt=prompt, options=options):
        if isinstance(message, ResultMessage):
            if hasattr(message, "result") and message.result:
                result_text = message.result
                break

    # Parse YAML response
    try:
        # Remove potential markdown code block markers
        result_text = result_text.strip()
        if result_text.startswith("```"):
            lines = result_text.split("\n")
            result_text = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

        return yaml.safe_load(result_text) or {}
    except Exception:
        return {"_raw": result_text}


def _update_project_sections(
    project_file: Path,
    updates: dict[str, Any],
    is_init: bool = False,
) -> list[str]:
    """Update project file sections with AI-generated content.

    Args:
        project_file: Path to project markdown file.
        updates: Dictionary with goal, tech_stack, current_progress, blockers.
        is_init: If True, overwrite all sections (init mode).

    Returns:
        List of updated section names.
    """
    post = frontmatter.load(project_file)
    content = post.content
    updated_sections: list[str] = []

    # Update goal section
    if "goal" in updates and (is_init or "## ç›®æ¨™" not in content):
        goal_text = (
            updates["goal"].strip() if isinstance(updates["goal"], str) else str(updates["goal"])
        )
        if "## ç›®æ¨™" in content:
            parts = content.split("## ç›®æ¨™")
            # Find the next section
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## ç›®æ¨™\n" + goal_text + rest[next_section:]
            else:
                content = parts[0] + "## ç›®æ¨™\n" + goal_text
        else:
            # Add after title
            lines = content.split("\n")
            insert_idx = 1 if lines[0].startswith("#") else 0
            lines.insert(insert_idx + 1, f"\n## ç›®æ¨™\n{goal_text}")
            content = "\n".join(lines)
        updated_sections.append("ç›®æ¨™")

    # Update tech_stack section
    if "tech_stack" in updates:
        tech_list = updates["tech_stack"]
        if isinstance(tech_list, list):
            tech_text = "\n".join(f"- {item}" for item in tech_list)
        else:
            tech_text = str(tech_list)

        if "## æŠ€è¡“æ£§" in content:
            parts = content.split("## æŠ€è¡“æ£§")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## æŠ€è¡“æ£§\n" + tech_text + rest[next_section:]
            else:
                content = parts[0] + "## æŠ€è¡“æ£§\n" + tech_text
            updated_sections.append("æŠ€è¡“æ£§")

    # Update current_progress section
    if "current_progress" in updates and is_init:
        progress_list = updates["current_progress"]
        if isinstance(progress_list, list):
            progress_text = "\n".join(f"- {item}" for item in progress_list)
        else:
            progress_text = str(progress_list)

        if "## ç•¶å‰é€²åº¦" in content:
            parts = content.split("## ç•¶å‰é€²åº¦")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## ç•¶å‰é€²åº¦\n" + progress_text + rest[next_section:]
            else:
                content = parts[0] + "## ç•¶å‰é€²åº¦\n" + progress_text
            updated_sections.append("ç•¶å‰é€²åº¦")

    # Update blockers section (only in init mode)
    if "blockers" in updates and is_init:
        blockers_list = updates["blockers"]
        if isinstance(blockers_list, list):
            blockers_text = "\n".join(f"- {item}" for item in blockers_list)
        else:
            blockers_text = str(blockers_list)

        if "## Blockers" in content:
            parts = content.split("## Blockers")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## Blockers\n" + blockers_text + rest[next_section:]
            else:
                content = parts[0] + "## Blockers\n" + blockers_text
            updated_sections.append("Blockers")

    # Add sync log entry
    date_str = datetime.now().strftime("%Y-%m-%d")
    mode_str = "init (å®Œæ•´åˆ†æž)" if is_init else "sync (å¢žé‡æ›´æ–°)"
    sync_entry = f"\n- ðŸ”„ [{mode_str}] å·²åŒæ­¥: {', '.join(updated_sections)}"

    if "## é€²åº¦æ—¥èªŒ" in content:
        # Check if today's entry already exists
        if f"### {date_str}" in content:
            # Append to existing date entry
            content = content.replace(f"### {date_str}\n", f"### {date_str}{sync_entry}\n")
        else:
            # Add new date entry
            parts = content.split("## é€²åº¦æ—¥èªŒ")
            new_entry = f"\n\n### {date_str}{sync_entry}"
            content = parts[0] + "## é€²åº¦æ—¥èªŒ" + new_entry + parts[1]
    else:
        content += f"\n\n## é€²åº¦æ—¥èªŒ\n\n### {date_str}{sync_entry}"

    post.content = content

    project_file.write_text(frontmatter.dumps(post), encoding="utf-8")

    return updated_sections


@tool(
    name="sync_project",
    description="å¾ž repo å…§å®¹åŒæ­¥å°ˆæ¡ˆè³‡è¨Šã€‚åˆ†æž READMEã€CLAUDE.mdã€ç¨‹å¼ç¢¼çµæ§‹ç­‰ï¼Œç”¨ AI ç”Ÿæˆ/æ›´æ–°å°ˆæ¡ˆæè¿°ã€æŠ€è¡“æ£§ã€é€²åº¦ã€‚åˆæ¬¡ä½¿ç”¨æœƒé€²è¡Œå®Œæ•´åˆ†æžã€‚",
    input_schema=SyncProjectInput.model_json_schema(),
)
async def sync_project(args: dict[str, Any]) -> dict[str, Any]:
    """Sync project information from repository content.

    åˆ†æž repo çš„ READMEã€CLAUDE.mdã€ç¨‹å¼ç¢¼çµæ§‹ç­‰ï¼Œ
    ç”¨ AI ç”Ÿæˆ/æ›´æ–°å°ˆæ¡ˆçš„ç›®æ¨™ã€æŠ€è¡“æ£§ã€é€²åº¦ç­‰è³‡è¨Šã€‚

    æ”¯æ´å…©ç¨®æ¨¡å¼ï¼š
    - init: å°ˆæ¡ˆå…§å®¹ç‚ºé è¨­å€¼æ™‚ï¼Œé€²è¡Œå®Œæ•´åˆ†æž
    - sync: å°ˆæ¡ˆå·²æœ‰å…§å®¹æ™‚ï¼Œé€²è¡Œå¢žé‡æ›´æ–°

    Args:
        args: Dictionary containing:
            - name: å°ˆæ¡ˆåç¨±
            - force: æ˜¯å¦å¼·åˆ¶è¦†å¯«ï¼ˆé è¨­ Falseï¼‰

    Returns:
        Tool response with sync summary.
    """
    try:
        validated = SyncProjectInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name
    force = validated.force

    # Find project file
    projects_dir = _get_projects_dir()
    project_file = None
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() == name.lower():
            project_file = md_file
            break

    if not project_file:
        available = [f.stem for f in projects_dir.glob("*.md")]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # Read project and get repo path
    post = frontmatter.load(project_file)
    repo_path = post.get("repo", "")

    if not repo_path:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} æ²’æœ‰è¨­å®š repo è·¯å¾‘ã€‚è«‹åœ¨ frontmatter ä¸­åŠ å…¥ repo æ¬„ä½ã€‚",
                }
            ],
            "is_error": True,
        }

    repo_path = Path(repo_path).expanduser()
    if not repo_path.exists():
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨ï¼š{repo_path}",
                }
            ],
            "is_error": True,
        }

    # Determine mode: init or sync
    is_init = force or _is_default_content(post.content)
    mode_name = "init (å®Œæ•´åˆ†æž)" if is_init else "sync (å¢žé‡æ›´æ–°)"

    # Collect repo info
    repo_info = await _collect_repo_info_full(repo_path, full_analysis=is_init)

    if not repo_info.get("readme"):
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} çš„ repo ä¸­æ‰¾ä¸åˆ° README.mdã€‚",
                }
            ],
            "is_error": True,
        }

    # Analyze with AI
    try:
        updates = await _analyze_repo_for_init(name, repo_info)
    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"AI åˆ†æžå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    if "_raw" in updates:
        # Failed to parse YAML
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"AI å›žæ‡‰æ ¼å¼éŒ¯èª¤ï¼Œè«‹æ‰‹å‹•æ›´æ–°ã€‚\n\nåŽŸå§‹å›žæ‡‰ï¼š\n{updates['_raw'][:1000]}",
                }
            ],
            "is_error": True,
        }

    # Update project file
    updated_sections = _update_project_sections(project_file, updates, is_init=is_init)

    # Build summary
    summary_lines = [
        f"## å·²åŒæ­¥ {name}",
        "",
        f"**æ¨¡å¼**: {mode_name}",
        f"**æ›´æ–°å€å¡Š**: {', '.join(updated_sections) if updated_sections else '(ç„¡è®Šæ›´)'}",
        "",
    ]

    if "goal" in updates:
        goal = updates["goal"].strip() if isinstance(updates["goal"], str) else str(updates["goal"])
        summary_lines.append(f"### ç›®æ¨™\n{goal}\n")

    if "tech_stack" in updates:
        tech = updates["tech_stack"]
        if isinstance(tech, list):
            summary_lines.append("### æŠ€è¡“æ£§")
            for item in tech[:5]:  # Show first 5
                summary_lines.append(f"- {item}")
            if len(tech) > 5:
                summary_lines.append(f"- ... å…± {len(tech)} é …")
            summary_lines.append("")

    summary_lines.append(f"å·²å¯«å…¥ {project_file}")

    return {
        "content": [{"type": "text", "text": "\n".join(summary_lines)}],
    }


# åŒ¯å‡ºæ‰€æœ‰å·¥å…·ï¼Œæ–¹ä¾¿ agent.py ä½¿ç”¨
all_tools = [
    list_projects,
    show_project,
    update_project_status,
    update_project_progress,
    sync_project,
]
