"""Project management tools for Komorebi.

å­¸ç¿’é‡é»ï¼š
- @tool decorator å®šç¾©å·¥å…·çš„ä¸‰å€‹åƒæ•¸ï¼šname, description, input_schema
- å·¥å…·å‡½æ•¸å¿…é ˆæ˜¯ async def
- å›å‚³æ ¼å¼ï¼š{"content": [{"type": "text", "text": "..."}]}
- éŒ¯èª¤æ™‚åŠ ä¸Š "is_error": True
- ä½¿ç”¨ Pydantic BaseModel é©—è­‰å·¥å…·è¼¸å…¥

é€™äº›å·¥å…·æ”¯æ´é›™æ¨¡å¼å°ˆæ¡ˆçµæ§‹ï¼š
- æª”æ¡ˆæ¨¡å¼ï¼šdata/projects/komorebi.mdï¼ˆèˆŠç‰ˆï¼‰
- è³‡æ–™å¤¾æ¨¡å¼ï¼šdata/projects/komorebi/project.md + tasks.mdï¼ˆæ–°ç‰ˆï¼‰
"""

import asyncio
import logging
import re
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any

import frontmatter
from claude_agent_sdk import ClaudeAgentOptions, query, tool
from claude_agent_sdk.types import ResultMessage
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)


# ============================================================================
# Pydantic Input Models
# ============================================================================


class ProjectStatus(str, Enum):
    """Valid project statuses."""

    ACTIVE = "active"
    PAUSED = "paused"
    COMPLETED = "completed"
    ARCHIVED = "archived"


class ShowProjectInput(BaseModel):
    """Input schema for show_project tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")


class UpdateStatusInput(BaseModel):
    """Input schema for update_project_status tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    status: ProjectStatus = Field(..., description="æ–°ç‹€æ…‹")


class UpdateProgressInput(BaseModel):
    """Input schema for update_project_progress tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    days: int = Field(default=1, ge=1, le=30, description="åˆ†ææœ€è¿‘å¹¾å¤©çš„è®Šæ›´")


class SyncProjectInput(BaseModel):
    """Input schema for sync_project tool."""

    name: str = Field(..., min_length=1, description="å°ˆæ¡ˆåç¨±")
    force: bool = Field(default=False, description="æ˜¯å¦å¼·åˆ¶è¦†å¯«")


# å°ˆæ¡ˆè³‡æ–™ç›®éŒ„ï¼Œç”± agent è¨­å®š
_data_dir: Path = Path("data")


def set_data_dir(path: Path) -> None:
    """Set the data directory for project tools.

    Args:
        path: Path to the data directory containing projects/.
    """
    global _data_dir
    _data_dir = path


def _get_projects_dir() -> Path:
    """Get the projects directory path."""
    return _data_dir / "projects"


# ============================================================================
# Dual-Mode Path Helpers
# ============================================================================


def _is_folder_mode(project_name: str) -> bool:
    """Check if a project uses folder mode.

    Args:
        project_name: Project name (case-insensitive).

    Returns:
        True if project uses folder mode (has project.md inside folder).
    """
    projects_dir = _get_projects_dir()

    # Check for folder mode: projects/komorebi/project.md
    folder_path = projects_dir / project_name.lower()
    if folder_path.is_dir() and (folder_path / "project.md").exists():
        return True

    return False


def _get_project_path(project_name: str) -> Path | None:
    """Get the project.md path for a project (supports both modes).

    Args:
        project_name: Project name (case-insensitive).

    Returns:
        Path to project.md or None if not found.
    """
    projects_dir = _get_projects_dir()
    name_lower = project_name.lower()

    # Priority 1: Folder mode (projects/komorebi/project.md)
    folder_path = projects_dir / name_lower / "project.md"
    if folder_path.exists():
        return folder_path

    # Priority 2: File mode (projects/komorebi.md)
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() == name_lower:
            return md_file

    return None


def _get_tasks_path(project_name: str) -> Path | None:
    """Get the tasks.md path for a project (folder mode only).

    Args:
        project_name: Project name (case-insensitive).

    Returns:
        Path to tasks.md or None if not in folder mode.
    """
    projects_dir = _get_projects_dir()
    tasks_path = projects_dir / project_name.lower() / "tasks.md"
    return tasks_path if tasks_path.exists() else None


def _get_project_folder(project_name: str) -> Path | None:
    """Get the project folder path (folder mode only).

    Args:
        project_name: Project name (case-insensitive).

    Returns:
        Path to project folder or None if not in folder mode.
    """
    projects_dir = _get_projects_dir()
    folder_path = projects_dir / project_name.lower()
    return folder_path if folder_path.is_dir() else None


def _iter_all_projects() -> list[tuple[str, Path, bool]]:
    """Iterate over all projects, both file and folder mode.

    Returns:
        List of (project_name, project_md_path, is_folder_mode) tuples.
    """
    projects_dir = _get_projects_dir()
    results: list[tuple[str, Path, bool]] = []

    if not projects_dir.exists():
        return results

    # Collect folder mode projects
    for item in projects_dir.iterdir():
        if item.is_dir():
            project_md = item / "project.md"
            if project_md.exists():
                results.append((item.name, project_md, True))

    # Collect file mode projects (exclude those already in folder mode)
    folder_names = {r[0] for r in results}
    for md_file in projects_dir.glob("*.md"):
        if md_file.stem.lower() not in folder_names:
            results.append((md_file.stem, md_file, False))

    return results


# ============================================================================
# Task Parsing Utilities
# ============================================================================


def _parse_tasks(tasks_content: str) -> dict[str, list[dict[str, Any]]]:
    """Parse tasks.md content into structured data.

    Args:
        tasks_content: Content of tasks.md file.

    Returns:
        Dictionary with 'in_progress', 'pending', 'completed' lists.
    """
    result: dict[str, list[dict[str, Any]]] = {
        "in_progress": [],
        "pending": [],
        "completed": [],
    }

    current_section = "pending"
    section_map = {
        "é€²è¡Œä¸­": "in_progress",
        "in progress": "in_progress",
        "å¾…è™•ç†": "pending",
        "pending": "pending",
        "todo": "pending",
        "å·²å®Œæˆ": "completed",
        "completed": "completed",
        "done": "completed",
    }

    # Parse task line: - [ ] task text #tag @today (2026-01-18)
    task_pattern = re.compile(
        r"^-\s*\[([ xX])\]\s*"  # checkbox
        r"(.+?)"  # task text
        r"(?:\s*\((\d{4}-\d{2}-\d{2})\))?\s*$"  # optional date
    )

    for line in tasks_content.split("\n"):
        line = line.strip()

        # Check for section headers
        if line.startswith("## "):
            section_name = line[3:].strip().lower()
            if section_name in section_map:
                current_section = section_map[section_name]
            continue

        # Check for task lines
        match = task_pattern.match(line)
        if match:
            checked = match.group(1).lower() == "x"
            text = match.group(2).strip()
            completed_date = match.group(3)

            # Extract tags (#tag)
            tags = re.findall(r"#(\S+)", text)
            text_clean = re.sub(r"\s*#\S+", "", text).strip()

            # Check for @today marker
            is_today = "@today" in text
            text_clean = text_clean.replace("@today", "").strip()

            task = {
                "text": text_clean,
                "completed": checked,
                "tags": tags,
                "is_today": is_today,
            }
            if completed_date:
                task["completed_date"] = completed_date

            # Put in appropriate section based on checkbox state
            if checked:
                result["completed"].append(task)
            else:
                result[current_section].append(task)

    return result


def _count_tasks(project_path: Path) -> dict[str, int]:
    """Count tasks for a project (supports both modes).

    Args:
        project_path: Path to project.md file.

    Returns:
        Dictionary with task counts.
    """
    counts = {"total": 0, "completed": 0, "in_progress": 0, "pending": 0}

    # Check if this is folder mode
    if project_path.name == "project.md":
        tasks_path = project_path.parent / "tasks.md"
        if tasks_path.exists():
            tasks = _parse_tasks(tasks_path.read_text(encoding="utf-8"))
            counts["in_progress"] = len(tasks["in_progress"])
            counts["pending"] = len(tasks["pending"])
            counts["completed"] = len(tasks["completed"])
            counts["total"] = sum(counts.values()) - counts["completed"]
            counts["total"] += counts["completed"]

    return counts


def _calculate_progress(project_path: Path) -> int:
    """Calculate progress percentage for a project.

    Args:
        project_path: Path to project.md file.

    Returns:
        Progress percentage (0-100).
    """
    counts = _count_tasks(project_path)
    if counts["total"] == 0:
        return 0
    return int((counts["completed"] / counts["total"]) * 100)


@tool(
    name="list_projects",
    description="åˆ—å‡ºæ‰€æœ‰å°ˆæ¡ˆåŠå…¶ç‹€æ…‹ã€é€²åº¦çµ±è¨ˆã€‚å›å‚³å°ˆæ¡ˆåç¨±ã€ç‹€æ…‹ã€å„ªå…ˆé †åºã€ä»»å‹™å®Œæˆç‡ç­‰æ‘˜è¦è³‡è¨Šã€‚",
    input_schema={},  # ç„¡åƒæ•¸
)
async def list_projects(args: dict[str, Any]) -> dict[str, Any]:
    """List all projects with statistics (supports both file and folder mode).

    è®€å–æ¯å€‹å°ˆæ¡ˆçš„ frontmatter å’Œä»»å‹™çµ±è¨ˆè³‡è¨Šã€‚

    Returns:
        Tool response with formatted project list and statistics.
    """
    projects_dir = _get_projects_dir()

    if not projects_dir.exists():
        return {
            "content": [
                {"type": "text", "text": "å°ˆæ¡ˆè³‡æ–™å¤¾ä¸å­˜åœ¨ã€‚è«‹å…ˆå»ºç«‹ data/projects/ ç›®éŒ„ã€‚"}
            ],
            "is_error": True,
        }

    projects: list[dict[str, Any]] = []

    for name, project_path, is_folder in _iter_all_projects():
        try:
            post = frontmatter.load(project_path)
            task_counts = _count_tasks(project_path)

            projects.append(
                {
                    "name": post.get("name", name),
                    "type": post.get("type", "software"),
                    "status": post.get("status", "unknown"),
                    "priority": post.get("priority", 999),
                    "progress": post.get("progress", _calculate_progress(project_path)),
                    "is_folder": is_folder,
                    "tasks": task_counts,
                }
            )
        except (OSError, IOError) as e:
            logger.warning(f"Failed to read {project_path}: {e}")
            projects.append(
                {
                    "name": name,
                    "type": "unknown",
                    "status": "error: file read failed",
                    "priority": 999,
                    "progress": 0,
                    "is_folder": is_folder,
                    "tasks": {"total": 0, "completed": 0},
                }
            )
        except (KeyError, ValueError) as e:
            logger.warning(f"Failed to parse frontmatter in {project_path}: {e}")
            projects.append(
                {
                    "name": name,
                    "type": "unknown",
                    "status": "error: invalid format",
                    "priority": 999,
                    "progress": 0,
                    "is_folder": is_folder,
                    "tasks": {"total": 0, "completed": 0},
                }
            )

    if not projects:
        return {
            "content": [{"type": "text", "text": "ç›®å‰æ²’æœ‰ä»»ä½•å°ˆæ¡ˆã€‚"}],
        }

    # æŒ‰å„ªå…ˆé †åºæ’åº
    projects.sort(key=lambda p: p["priority"])

    # æ ¼å¼åŒ–è¼¸å‡º
    lines = ["## å°ˆæ¡ˆåˆ—è¡¨\n"]
    for p in projects:
        status_emoji = {
            "active": "ğŸŸ¢",
            "paused": "â¸ï¸",
            "completed": "âœ…",
            "archived": "ğŸ“¦",
        }.get(p["status"], "â“")

        # Build stats string
        stats_parts = []
        if p["tasks"]["total"] > 0:
            stats_parts.append(f"{p['tasks']['completed']}/{p['tasks']['total']} tasks")
        if p["progress"] > 0:
            stats_parts.append(f"{p['progress']}%")
        stats = f" | {', '.join(stats_parts)}" if stats_parts else ""

        # Mode indicator
        mode = "ğŸ“" if p["is_folder"] else "ğŸ“„"

        lines.append(f"- {status_emoji} {mode} **{p['name']}** ({p['status']}){stats}")

    return {
        "content": [{"type": "text", "text": "\n".join(lines)}],
    }


@tool(
    name="show_project",
    description="é¡¯ç¤ºå–®ä¸€å°ˆæ¡ˆçš„å®Œæ•´è³‡è¨Šï¼ŒåŒ…å«ç›®æ¨™ã€æŠ€è¡“æ£§ã€é€²åº¦ã€ä»»å‹™æ¸…å–®ç­‰è©³ç´°å…§å®¹ã€‚æ”¯æ´æª”æ¡ˆå’Œè³‡æ–™å¤¾å…©ç¨®æ¨¡å¼ã€‚",
    input_schema=ShowProjectInput.model_json_schema(),
)
async def show_project(args: dict[str, Any]) -> dict[str, Any]:
    """Show detailed information about a specific project.

    æ”¯æ´é›™æ¨¡å¼ï¼š
    - æª”æ¡ˆæ¨¡å¼ï¼šå›å‚³ project.md å…§å®¹
    - è³‡æ–™å¤¾æ¨¡å¼ï¼šå›å‚³ project.md + tasks.md å…§å®¹

    Args:
        args: Dictionary containing 'name' - the project name (case-insensitive).

    Returns:
        Tool response with project details.
    """
    try:
        validated = ShowProjectInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name
    project_path = _get_project_path(name)

    if not project_path:
        # åˆ—å‡ºå¯ç”¨çš„å°ˆæ¡ˆ
        available = [p[0] for p in _iter_all_projects()]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # Read project.md
    content = project_path.read_text(encoding="utf-8")

    # Check if folder mode - include tasks.md if exists
    is_folder = project_path.name == "project.md"
    if is_folder:
        tasks_path = project_path.parent / "tasks.md"
        if tasks_path.exists():
            tasks_content = tasks_path.read_text(encoding="utf-8")
            content += f"\n\n---\n\n# ä»»å‹™æ¸…å–® (tasks.md)\n\n{tasks_content}"

        # Add folder info
        folder_path = project_path.parent
        files = list(folder_path.iterdir())
        content += f"\n\n---\n\n**å°ˆæ¡ˆè³‡æ–™å¤¾**: `{folder_path}`\n"
        content += f"**æª”æ¡ˆ**: {', '.join(f.name for f in files)}"

    return {
        "content": [{"type": "text", "text": content}],
    }


@tool(
    name="get_today_tasks",
    description="å–å¾—ä»Šæ—¥ä»»å‹™æ¸…å–®ï¼ˆè·¨æ‰€æœ‰å°ˆæ¡ˆï¼‰ã€‚æƒææ‰€æœ‰å°ˆæ¡ˆçš„ tasks.mdï¼Œæ‰¾å‡ºæ¨™è¨˜ @today çš„ä»»å‹™å’Œé€²è¡Œä¸­çš„ä»»å‹™ã€‚",
    input_schema={},  # ç„¡åƒæ•¸
)
async def get_today_tasks(args: dict[str, Any]) -> dict[str, Any]:
    """Get today's tasks across all projects.

    æƒææ‰€æœ‰å°ˆæ¡ˆï¼ˆfolder modeï¼‰çš„ tasks.mdï¼Œæ‰¾å‡ºï¼š
    1. æ¨™è¨˜ @today çš„ä»»å‹™
    2. é€²è¡Œä¸­çš„ä»»å‹™

    Returns:
        Tool response with today's task list.
    """
    today_tasks: list[dict[str, Any]] = []
    in_progress_tasks: list[dict[str, Any]] = []

    for name, project_path, is_folder in _iter_all_projects():
        if not is_folder:
            continue  # Only check folder mode projects

        tasks_path = project_path.parent / "tasks.md"
        if not tasks_path.exists():
            continue

        try:
            tasks_content = tasks_path.read_text(encoding="utf-8")
            parsed = _parse_tasks(tasks_content)

            # Collect @today tasks
            for task in parsed["pending"] + parsed["in_progress"]:
                if task.get("is_today"):
                    today_tasks.append(
                        {
                            "project": name,
                            "text": task["text"],
                            "tags": task.get("tags", []),
                            "section": "in_progress"
                            if task in parsed["in_progress"]
                            else "pending",
                        }
                    )

            # Collect all in-progress tasks
            for task in parsed["in_progress"]:
                if not task.get("is_today"):  # Avoid duplicates
                    in_progress_tasks.append(
                        {
                            "project": name,
                            "text": task["text"],
                            "tags": task.get("tags", []),
                        }
                    )

        except (OSError, IOError) as e:
            logger.warning(f"Failed to read tasks for {name}: {e}")

    # Format output
    lines = ["## ä»Šæ—¥ä»»å‹™\n"]

    if today_tasks:
        lines.append("### @today æ¨™è¨˜\n")
        for t in today_tasks:
            tags = " ".join(f"#{tag}" for tag in t["tags"]) if t["tags"] else ""
            lines.append(f"- [ ] **{t['project']}**: {t['text']} {tags}")
    else:
        lines.append("_æ²’æœ‰æ¨™è¨˜ @today çš„ä»»å‹™_\n")

    if in_progress_tasks:
        lines.append("\n### é€²è¡Œä¸­\n")
        for t in in_progress_tasks:
            tags = " ".join(f"#{tag}" for tag in t["tags"]) if t["tags"] else ""
            lines.append(f"- [ ] **{t['project']}**: {t['text']} {tags}")

    if not today_tasks and not in_progress_tasks:
        lines.append("\n_ç›®å‰æ²’æœ‰ä»»ä½•é€²è¡Œä¸­æˆ–ä»Šæ—¥å¾…è¾¦çš„ä»»å‹™ã€‚_")

    return {
        "content": [{"type": "text", "text": "\n".join(lines)}],
    }


@tool(
    name="update_project_status",
    description="æ›´æ–°å°ˆæ¡ˆçš„ç‹€æ…‹ï¼ˆactive, paused, completed, archivedï¼‰ã€‚æ”¯æ´æª”æ¡ˆå’Œè³‡æ–™å¤¾å…©ç¨®æ¨¡å¼ã€‚",
    input_schema=UpdateStatusInput.model_json_schema(),
)
async def update_project_status(args: dict[str, Any]) -> dict[str, Any]:
    """Update the status of a project.

    ä¿®æ”¹å°ˆæ¡ˆ markdown æª”æ¡ˆçš„ frontmatter ä¸­çš„ status æ¬„ä½ã€‚
    æ”¯æ´æª”æ¡ˆå’Œè³‡æ–™å¤¾å…©ç¨®æ¨¡å¼ã€‚

    Args:
        args: Dictionary containing 'name' and 'status'.

    Returns:
        Tool response confirming the update.
    """
    try:
        validated = UpdateStatusInput(**args)
    except ValueError as e:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}\næœ‰æ•ˆç‹€æ…‹ï¼šactive, paused, completed, archived",
                }
            ],
            "is_error": True,
        }

    name = validated.name
    new_status = validated.status.value

    project_file = _get_project_path(name)

    if not project_file:
        available = [p[0] for p in _iter_all_projects()]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # è®€å–ä¸¦æ›´æ–°
    try:
        post = frontmatter.load(project_file)
        old_status = post.get("status", "unknown")
        post["status"] = new_status
        post["updated"] = datetime.now().strftime("%Y-%m-%d")

        project_file.write_text(frontmatter.dumps(post), encoding="utf-8")

        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å·²æ›´æ–° **{name}** ç‹€æ…‹ï¼š{old_status} â†’ {new_status}",
                }
            ],
        }
    except (OSError, IOError) as e:
        logger.error(f"Failed to write project file {project_file}: {e}")
        return {
            "content": [{"type": "text", "text": f"å¯«å…¥æª”æ¡ˆå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }
    except (KeyError, ValueError) as e:
        logger.error(f"Failed to parse frontmatter in {project_file}: {e}")
        return {
            "content": [{"type": "text", "text": f"æª”æ¡ˆæ ¼å¼éŒ¯èª¤ï¼š{e}"}],
            "is_error": True,
        }


# ============================================================================
# Progress Analysis Tool
# ============================================================================


async def _run_git_command(repo_path: Path, args: list[str]) -> str:
    """Run a git command asynchronously and return output.

    Args:
        repo_path: Path to the git repository.
        args: Git command arguments.

    Returns:
        Command output or empty string on error.
    """
    try:
        process = await asyncio.create_subprocess_exec(
            "git",
            *args,
            cwd=repo_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.DEVNULL,
        )
        stdout, _ = await asyncio.wait_for(process.communicate(), timeout=30)
        if process.returncode == 0:
            return stdout.decode().strip()
    except asyncio.TimeoutError:
        logger.warning(f"Git command timed out: git {' '.join(args)}")
    except FileNotFoundError:
        logger.warning("Git executable not found")
    except OSError as e:
        logger.warning(f"Git command failed: {e}")
    return ""


async def _collect_git_info(repo_path: Path, days: int = 1) -> dict[str, str]:
    """Collect git log and diff information asynchronously.

    Args:
        repo_path: Path to the git repository.
        days: Number of days to look back.

    Returns:
        Dictionary with log, diff, and changed_files.
    """
    # Run git commands in parallel for better performance
    log_task = _run_git_command(repo_path, ["log", f"--since={days} days ago", "--oneline"])
    diff_task = _run_git_command(repo_path, ["diff", f"HEAD~{days}", "--stat"])
    diff_content_task = _run_git_command(repo_path, ["diff", f"HEAD~{days}"])
    changed_files_task = _run_git_command(repo_path, ["diff", "--name-only", f"HEAD~{days}"])

    log, diff, diff_content, changed_files = await asyncio.gather(
        log_task, diff_task, diff_content_task, changed_files_task
    )

    return {
        "log": log,
        "diff": diff,
        "diff_content": diff_content,
        "changed_files": changed_files,
    }


async def _analyze_with_sonnet(project_name: str, git_info: dict[str, str]) -> str:
    """Use Sonnet to analyze project progress.

    Args:
        project_name: Name of the project.
        git_info: Dictionary with git information.

    Returns:
        Progress summary in Traditional Chinese.
    """
    # é™åˆ¶ diff é•·åº¦é¿å… token éå¤š
    diff_content = git_info["diff_content"][:4000] if git_info["diff_content"] else "(ç„¡è®Šæ›´)"

    prompt = f"""åˆ†æä»¥ä¸‹å°ˆæ¡ˆçš„é€²åº¦ï¼Œç”¨ç¹é«”ä¸­æ–‡æ’°å¯«ç°¡æ½”çš„é€²åº¦æ‘˜è¦ï¼ˆ3-5 å€‹ bullet pointsï¼‰ã€‚

## å°ˆæ¡ˆï¼š{project_name}

## Git Commits
{git_info["log"] or "(ç„¡ commits)"}

## æª”æ¡ˆè®Šæ›´çµ±è¨ˆ
{git_info["diff"] or "(ç„¡è®Šæ›´)"}

## ç¨‹å¼ç¢¼è®Šæ›´å…§å®¹
{diff_content}

è«‹ç›´æ¥è¼¸å‡ºé€²åº¦æ‘˜è¦ï¼Œä¸è¦æœ‰é–‹é ­èªæˆ–çµå°¾èªã€‚æ ¼å¼ï¼š
- ç¬¬ä¸€é …é€²åº¦
- ç¬¬äºŒé …é€²åº¦
..."""

    options = ClaudeAgentOptions(model="claude-sonnet-4-5-20250929")
    result_text = ""

    async for message in query(prompt=prompt, options=options):
        if isinstance(message, ResultMessage):
            # å¾ ResultMessage ä¸­æå–æ–‡å­—
            if hasattr(message, "result") and message.result:
                result_text = message.result
                break

    return result_text


def _append_progress_log(project_file: Path, date_str: str, summary: str) -> None:
    """Append progress summary to project's progress log.

    Args:
        project_file: Path to the project markdown file.
        date_str: Date string (YYYY-MM-DD).
        summary: Progress summary to append.
    """
    post = frontmatter.load(project_file)
    content = post.content

    # æ‰¾åˆ° "## é€²åº¦æ—¥èªŒ" å€å¡Š
    if "## é€²åº¦æ—¥èªŒ" in content:
        # åœ¨ "## é€²åº¦æ—¥èªŒ" å¾Œæ’å…¥æ–°æ—¥èªŒ
        parts = content.split("## é€²åº¦æ—¥èªŒ")
        new_entry = f"\n\n### {date_str}\n{summary}"
        content = parts[0] + "## é€²åº¦æ—¥èªŒ" + new_entry + parts[1]
    else:
        # å¦‚æœæ²’æœ‰é€²åº¦æ—¥èªŒå€å¡Šï¼Œåœ¨æœ€å¾ŒåŠ ä¸Š
        content += f"\n\n## é€²åº¦æ—¥èªŒ\n\n### {date_str}\n{summary}"

    post.content = content

    project_file.write_text(frontmatter.dumps(post), encoding="utf-8")


@tool(
    name="update_project_progress",
    description="ç”¨ AI åˆ†æå°ˆæ¡ˆçš„ git è®Šæ›´ï¼Œè‡ªå‹•æ’°å¯«é€²åº¦æ—¥èªŒã€‚æœƒç ”ç©¶ commits å’Œç¨‹å¼ç¢¼è®Šæ›´å¾Œç”Ÿæˆæ‘˜è¦ã€‚",
    input_schema=UpdateProgressInput.model_json_schema(),
)
async def update_project_progress(args: dict[str, Any]) -> dict[str, Any]:
    """Analyze project git changes and update progress log.

    ä½¿ç”¨ Sonnet åˆ†æå°ˆæ¡ˆçš„ git commits å’Œç¨‹å¼ç¢¼è®Šæ›´ï¼Œ
    è‡ªå‹•ç”Ÿæˆé€²åº¦æ‘˜è¦ä¸¦å¯«å…¥å°ˆæ¡ˆçš„é€²åº¦æ—¥èªŒã€‚

    Args:
        args: Dictionary containing:
            - name: å°ˆæ¡ˆåç¨±
            - days: åˆ†ææœ€è¿‘å¹¾å¤©çš„è®Šæ›´ï¼ˆé è¨­ 1ï¼‰

    Returns:
        Tool response with generated progress summary.
    """
    try:
        validated = UpdateProgressInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name
    days = validated.days

    # æ‰¾åˆ°å°ˆæ¡ˆæª”æ¡ˆï¼ˆæ”¯æ´æª”æ¡ˆå’Œè³‡æ–™å¤¾å…©ç¨®æ¨¡å¼ï¼‰
    project_file = _get_project_path(name)

    if not project_file:
        available = [p[0] for p in _iter_all_projects()]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # è®€å–å°ˆæ¡ˆçš„ repo è·¯å¾‘
    post = frontmatter.load(project_file)
    repo_path = post.get("repo", "")

    if not repo_path:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} æ²’æœ‰è¨­å®š repo è·¯å¾‘ã€‚è«‹åœ¨ frontmatter ä¸­åŠ å…¥ repo æ¬„ä½ã€‚",
                }
            ],
            "is_error": True,
        }

    # å±•é–‹è·¯å¾‘
    repo_path = Path(repo_path).expanduser()
    if not repo_path.exists():
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨ï¼š{repo_path}",
                }
            ],
            "is_error": True,
        }

    # æ”¶é›† git è³‡è¨Š
    git_info = await _collect_git_info(repo_path, days)

    if not git_info["log"]:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} åœ¨æœ€è¿‘ {days} å¤©å…§æ²’æœ‰ commitsã€‚",
                }
            ],
        }

    # ç”¨ Sonnet åˆ†æ
    try:
        summary = await _analyze_with_sonnet(name, git_info)
    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"AI åˆ†æå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    # æ›´æ–°é€²åº¦æ—¥èªŒ
    date_str = datetime.now().strftime("%Y-%m-%d")
    _append_progress_log(project_file, date_str, summary)

    return {
        "content": [
            {
                "type": "text",
                "text": f"""## å·²æ›´æ–° {name} çš„é€²åº¦æ—¥èªŒ

**æ—¥æœŸ**: {date_str}
**åˆ†æç¯„åœ**: æœ€è¿‘ {days} å¤©
**Commits**: {len(git_info["log"].splitlines())} ç­†

### é€²åº¦æ‘˜è¦
{summary}

å·²å¯«å…¥ {project_file}""",
            }
        ],
    }


# ============================================================================
# Project Sync Tool
# ============================================================================


def _read_file_safely(file_path: Path, max_chars: int = 4000) -> str:
    """Read file content with size limit.

    Args:
        file_path: Path to file.
        max_chars: Maximum characters to read.

    Returns:
        File content (truncated if needed) or empty string.
    """
    if not file_path.exists():
        return ""
    try:
        content = file_path.read_text(encoding="utf-8")
        if len(content) > max_chars:
            return content[:max_chars] + "\n...(truncated)"
        return content
    except Exception:
        return ""


async def _collect_repo_info_full(repo_path: Path, full_analysis: bool = False) -> dict[str, str]:
    """Collect comprehensive repository information asynchronously.

    Args:
        repo_path: Path to the repository.
        full_analysis: If True, collect more data for init mode.

    Returns:
        Dictionary with readme, claude_md, other_docs, dependencies,
        structure, git_log.
    """
    info: dict[str, str] = {}

    # README
    info["readme"] = _read_file_safely(repo_path / "README.md")

    # CLAUDE.md (if exists)
    info["claude_md"] = _read_file_safely(repo_path / "CLAUDE.md")

    # Dependencies (pyproject.toml or package.json)
    deps_file = repo_path / "pyproject.toml"
    if not deps_file.exists():
        deps_file = repo_path / "package.json"
    info["dependencies"] = _read_file_safely(deps_file, max_chars=2000)

    # Directory structure
    info["structure"] = await _run_git_command(
        repo_path,
        ["-c", "core.quotepath=false", "ls-tree", "-r", "--name-only", "HEAD"],
    )
    if not info["structure"]:
        # Fallback: use find command asynchronously
        try:
            process = await asyncio.create_subprocess_exec(
                "find",
                ".",
                "-maxdepth",
                "3",
                "-type",
                "f",
                "-name",
                "*.py",
                cwd=repo_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.DEVNULL,
            )
            stdout, _ = await asyncio.wait_for(process.communicate(), timeout=10)
            info["structure"] = stdout.decode().strip()
        except (asyncio.TimeoutError, OSError) as e:
            logger.warning(f"Failed to get directory structure: {e}")
            info["structure"] = "(ç„¡æ³•å–å¾—ç›®éŒ„çµæ§‹)"

    # Git log
    if full_analysis:
        # Full history for init mode
        info["git_log"] = await _run_git_command(repo_path, ["log", "--oneline", "-50"])
        # Other docs
        other_docs = []
        for doc_name in ["TECHNICAL.md", "API_SPEC.md", "ARCHITECTURE.md"]:
            doc_content = _read_file_safely(repo_path / doc_name, max_chars=2000)
            if doc_content:
                other_docs.append(f"### {doc_name}\n{doc_content}")
        info["other_docs"] = "\n\n".join(other_docs) if other_docs else "(ç„¡)"
    else:
        # Recent history for sync mode
        info["git_log"] = await _run_git_command(
            repo_path, ["log", "--since=7 days ago", "--oneline"]
        )
        info["other_docs"] = "(sync mode: ç•¥é)"

    return info


def _is_default_content(content: str) -> bool:
    """Check if project content contains default/placeholder values.

    Args:
        content: Project markdown content.

    Returns:
        True if content appears to be default/placeholder.
    """
    default_markers = [
        "Layer-wise training framework",  # LayerWise çš„éŒ¯èª¤é è¨­æè¿°
        "å¾…å¡«å¯«",
        "TODO:",
        "(ç„¡å…§å®¹)",
        "Description here",
        "Add description",
    ]
    return any(marker.lower() in content.lower() for marker in default_markers)


INIT_PROMPT = """ä½ æ˜¯å°ˆæ¡ˆåˆ†æåŠ©ç†ã€‚æ ¹æ“šä»¥ä¸‹ repository è³‡è¨Šï¼Œç‚ºé€™å€‹æˆç†Ÿå°ˆæ¡ˆç”Ÿæˆå®Œæ•´çš„å°ˆæ¡ˆæ–‡ä»¶ã€‚

## Repository è³‡è¨Š

### README
{readme}

### é–‹ç™¼æŒ‡å— (CLAUDE.md)
{claude_md}

### å…¶ä»–æ–‡æª”
{other_docs}

### ä¾è³´é…ç½®
{dependencies}

### ç›®éŒ„çµæ§‹
{structure}

### Git é–‹ç™¼æ­·å²
{git_log}

## è¼¸å‡ºæ ¼å¼ (YAML)

è«‹ç”¨ YAML æ ¼å¼è¼¸å‡ºä»¥ä¸‹æ¬„ä½ï¼ˆç¹é«”ä¸­æ–‡ï¼‰ã€‚ç›´æ¥è¼¸å‡º YAML å…§å®¹ï¼Œä¸è¦æœ‰ ```yaml æ¨™è¨˜ï¼š

goal: |
  å°ˆæ¡ˆçš„æ ¸å¿ƒç›®æ¨™èˆ‡åƒ¹å€¼ä¸»å¼µï¼ˆ2-3 å¥ï¼‰

tech_stack:
  - "Language: Python 3.12"
  - "Framework: FastAPI"
  - "Core: pypotrace (å‘é‡ææ‘¹)"
  # åˆ—å‡ºæ‰€æœ‰é—œéµæŠ€è¡“ï¼Œé™„ä¸Šç”¨é€”èªªæ˜

current_progress:
  - "[x] å·²å®Œæˆçš„åŠŸèƒ½"
  - "[ ] é€²è¡Œä¸­æˆ–å¾…è¾¦çš„åŠŸèƒ½"
  # æ ¹æ“šç¨‹å¼ç¢¼çµæ§‹å’Œ git history æ¨æ¸¬

blockers:
  - "(ç„¡)"
  # æˆ–æè¿°ç™¼ç¾çš„æ½›åœ¨å•é¡Œ

æ³¨æ„ï¼š
1. goal è¦ç²¾ç¢ºæè¿°å°ˆæ¡ˆç›®çš„å’Œæ ¸å¿ƒåƒ¹å€¼
2. tech_stack è¦å®Œæ•´ï¼Œæ¯é …é™„ä¸Šç”¨é€”
3. current_progress æ ¹æ“šç¨‹å¼ç¢¼çµæ§‹æ¨æ¸¬å®Œæˆåº¦
4. ç›´æ¥è¼¸å‡º YAMLï¼Œé–‹é ­æ˜¯ goal:
"""


async def _analyze_repo_for_init(
    project_name: str,
    repo_info: dict[str, str],
) -> dict[str, Any]:
    """Use Sonnet to analyze repository for init mode.

    Args:
        project_name: Name of the project.
        repo_info: Collected repository information.

    Returns:
        Parsed YAML as dictionary, or empty dict on error.
    """
    import yaml

    prompt = INIT_PROMPT.format(
        readme=repo_info.get("readme", "(ç„¡)"),
        claude_md=repo_info.get("claude_md", "(ç„¡)"),
        other_docs=repo_info.get("other_docs", "(ç„¡)"),
        dependencies=repo_info.get("dependencies", "(ç„¡)"),
        structure=repo_info.get("structure", "(ç„¡)"),
        git_log=repo_info.get("git_log", "(ç„¡)"),
    )

    options = ClaudeAgentOptions(model="claude-sonnet-4-5-20250929")
    result_text = ""

    async for message in query(prompt=prompt, options=options):
        if isinstance(message, ResultMessage):
            if hasattr(message, "result") and message.result:
                result_text = message.result
                break

    # Parse YAML response
    try:
        # Remove potential markdown code block markers
        result_text = result_text.strip()
        if result_text.startswith("```"):
            lines = result_text.split("\n")
            result_text = "\n".join(lines[1:-1] if lines[-1] == "```" else lines[1:])

        return yaml.safe_load(result_text) or {}
    except Exception:
        return {"_raw": result_text}


def _update_project_sections(
    project_file: Path,
    updates: dict[str, Any],
    is_init: bool = False,
) -> list[str]:
    """Update project file sections with AI-generated content.

    Args:
        project_file: Path to project markdown file.
        updates: Dictionary with goal, tech_stack, current_progress, blockers.
        is_init: If True, overwrite all sections (init mode).

    Returns:
        List of updated section names.
    """
    post = frontmatter.load(project_file)
    content = post.content
    updated_sections: list[str] = []

    # Update goal section
    if "goal" in updates and (is_init or "## ç›®æ¨™" not in content):
        goal_text = (
            updates["goal"].strip() if isinstance(updates["goal"], str) else str(updates["goal"])
        )
        if "## ç›®æ¨™" in content:
            parts = content.split("## ç›®æ¨™")
            # Find the next section
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## ç›®æ¨™\n" + goal_text + rest[next_section:]
            else:
                content = parts[0] + "## ç›®æ¨™\n" + goal_text
        else:
            # Add after title
            lines = content.split("\n")
            insert_idx = 1 if lines[0].startswith("#") else 0
            lines.insert(insert_idx + 1, f"\n## ç›®æ¨™\n{goal_text}")
            content = "\n".join(lines)
        updated_sections.append("ç›®æ¨™")

    # Update tech_stack section
    if "tech_stack" in updates:
        tech_list = updates["tech_stack"]
        if isinstance(tech_list, list):
            tech_text = "\n".join(f"- {item}" for item in tech_list)
        else:
            tech_text = str(tech_list)

        if "## æŠ€è¡“æ£§" in content:
            parts = content.split("## æŠ€è¡“æ£§")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## æŠ€è¡“æ£§\n" + tech_text + rest[next_section:]
            else:
                content = parts[0] + "## æŠ€è¡“æ£§\n" + tech_text
            updated_sections.append("æŠ€è¡“æ£§")

    # Update current_progress section
    if "current_progress" in updates and is_init:
        progress_list = updates["current_progress"]
        if isinstance(progress_list, list):
            progress_text = "\n".join(f"- {item}" for item in progress_list)
        else:
            progress_text = str(progress_list)

        if "## ç•¶å‰é€²åº¦" in content:
            parts = content.split("## ç•¶å‰é€²åº¦")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## ç•¶å‰é€²åº¦\n" + progress_text + rest[next_section:]
            else:
                content = parts[0] + "## ç•¶å‰é€²åº¦\n" + progress_text
            updated_sections.append("ç•¶å‰é€²åº¦")

    # Update blockers section (only in init mode)
    if "blockers" in updates and is_init:
        blockers_list = updates["blockers"]
        if isinstance(blockers_list, list):
            blockers_text = "\n".join(f"- {item}" for item in blockers_list)
        else:
            blockers_text = str(blockers_list)

        if "## Blockers" in content:
            parts = content.split("## Blockers")
            rest = parts[1]
            next_section = rest.find("\n## ")
            if next_section != -1:
                content = parts[0] + "## Blockers\n" + blockers_text + rest[next_section:]
            else:
                content = parts[0] + "## Blockers\n" + blockers_text
            updated_sections.append("Blockers")

    # Add sync log entry
    date_str = datetime.now().strftime("%Y-%m-%d")
    mode_str = "init (å®Œæ•´åˆ†æ)" if is_init else "sync (å¢é‡æ›´æ–°)"
    sync_entry = f"\n- ğŸ”„ [{mode_str}] å·²åŒæ­¥: {', '.join(updated_sections)}"

    if "## é€²åº¦æ—¥èªŒ" in content:
        # Check if today's entry already exists
        if f"### {date_str}" in content:
            # Append to existing date entry
            content = content.replace(f"### {date_str}\n", f"### {date_str}{sync_entry}\n")
        else:
            # Add new date entry
            parts = content.split("## é€²åº¦æ—¥èªŒ")
            new_entry = f"\n\n### {date_str}{sync_entry}"
            content = parts[0] + "## é€²åº¦æ—¥èªŒ" + new_entry + parts[1]
    else:
        content += f"\n\n## é€²åº¦æ—¥èªŒ\n\n### {date_str}{sync_entry}"

    post.content = content

    project_file.write_text(frontmatter.dumps(post), encoding="utf-8")

    return updated_sections


@tool(
    name="sync_project",
    description="å¾ repo å…§å®¹åŒæ­¥å°ˆæ¡ˆè³‡è¨Šã€‚åˆ†æ READMEã€CLAUDE.mdã€ç¨‹å¼ç¢¼çµæ§‹ç­‰ï¼Œç”¨ AI ç”Ÿæˆ/æ›´æ–°å°ˆæ¡ˆæè¿°ã€æŠ€è¡“æ£§ã€é€²åº¦ã€‚åˆæ¬¡ä½¿ç”¨æœƒé€²è¡Œå®Œæ•´åˆ†æã€‚",
    input_schema=SyncProjectInput.model_json_schema(),
)
async def sync_project(args: dict[str, Any]) -> dict[str, Any]:
    """Sync project information from repository content.

    åˆ†æ repo çš„ READMEã€CLAUDE.mdã€ç¨‹å¼ç¢¼çµæ§‹ç­‰ï¼Œ
    ç”¨ AI ç”Ÿæˆ/æ›´æ–°å°ˆæ¡ˆçš„ç›®æ¨™ã€æŠ€è¡“æ£§ã€é€²åº¦ç­‰è³‡è¨Šã€‚

    æ”¯æ´å…©ç¨®æ¨¡å¼ï¼š
    - init: å°ˆæ¡ˆå…§å®¹ç‚ºé è¨­å€¼æ™‚ï¼Œé€²è¡Œå®Œæ•´åˆ†æ
    - sync: å°ˆæ¡ˆå·²æœ‰å…§å®¹æ™‚ï¼Œé€²è¡Œå¢é‡æ›´æ–°

    Args:
        args: Dictionary containing:
            - name: å°ˆæ¡ˆåç¨±
            - force: æ˜¯å¦å¼·åˆ¶è¦†å¯«ï¼ˆé è¨­ Falseï¼‰

    Returns:
        Tool response with sync summary.
    """
    try:
        validated = SyncProjectInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    name = validated.name
    force = validated.force

    # Find project file (supports both file and folder mode)
    project_file = _get_project_path(name)

    if not project_file:
        available = [p[0] for p in _iter_all_projects()]
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"æ‰¾ä¸åˆ°å°ˆæ¡ˆï¼š{name}\nå¯ç”¨çš„å°ˆæ¡ˆï¼š{', '.join(available) if available else '(ç„¡)'}",
                }
            ],
            "is_error": True,
        }

    # Read project and get repo path
    post = frontmatter.load(project_file)
    repo_path = post.get("repo", "")

    if not repo_path:
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} æ²’æœ‰è¨­å®š repo è·¯å¾‘ã€‚è«‹åœ¨ frontmatter ä¸­åŠ å…¥ repo æ¬„ä½ã€‚",
                }
            ],
            "is_error": True,
        }

    repo_path = Path(repo_path).expanduser()
    if not repo_path.exists():
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆè·¯å¾‘ä¸å­˜åœ¨ï¼š{repo_path}",
                }
            ],
            "is_error": True,
        }

    # Determine mode: init or sync
    is_init = force or _is_default_content(post.content)
    mode_name = "init (å®Œæ•´åˆ†æ)" if is_init else "sync (å¢é‡æ›´æ–°)"

    # Collect repo info
    repo_info = await _collect_repo_info_full(repo_path, full_analysis=is_init)

    if not repo_info.get("readme"):
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"å°ˆæ¡ˆ {name} çš„ repo ä¸­æ‰¾ä¸åˆ° README.mdã€‚",
                }
            ],
            "is_error": True,
        }

    # Analyze with AI
    try:
        updates = await _analyze_repo_for_init(name, repo_info)
    except Exception as e:
        return {
            "content": [{"type": "text", "text": f"AI åˆ†æå¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    if "_raw" in updates:
        # Failed to parse YAML
        return {
            "content": [
                {
                    "type": "text",
                    "text": f"AI å›æ‡‰æ ¼å¼éŒ¯èª¤ï¼Œè«‹æ‰‹å‹•æ›´æ–°ã€‚\n\nåŸå§‹å›æ‡‰ï¼š\n{updates['_raw'][:1000]}",
                }
            ],
            "is_error": True,
        }

    # Update project file
    updated_sections = _update_project_sections(project_file, updates, is_init=is_init)

    # Build summary
    summary_lines = [
        f"## å·²åŒæ­¥ {name}",
        "",
        f"**æ¨¡å¼**: {mode_name}",
        f"**æ›´æ–°å€å¡Š**: {', '.join(updated_sections) if updated_sections else '(ç„¡è®Šæ›´)'}",
        "",
    ]

    if "goal" in updates:
        goal = updates["goal"].strip() if isinstance(updates["goal"], str) else str(updates["goal"])
        summary_lines.append(f"### ç›®æ¨™\n{goal}\n")

    if "tech_stack" in updates:
        tech = updates["tech_stack"]
        if isinstance(tech, list):
            summary_lines.append("### æŠ€è¡“æ£§")
            for item in tech[:5]:  # Show first 5
                summary_lines.append(f"- {item}")
            if len(tech) > 5:
                summary_lines.append(f"- ... å…± {len(tech)} é …")
            summary_lines.append("")

    summary_lines.append(f"å·²å¯«å…¥ {project_file}")

    return {
        "content": [{"type": "text", "text": "\n".join(summary_lines)}],
    }


# ============================================================================
# Review Tools
# ============================================================================


class WeeklyReviewInput(BaseModel):
    """Input schema for weekly_review tool."""

    week: str | None = Field(
        default=None,
        description="é€±æ¬¡ (æ ¼å¼: 2026-W03)ï¼Œé è¨­ç‚ºæœ¬é€±",
    )


class MonthlyReviewInput(BaseModel):
    """Input schema for monthly_review tool."""

    month: str | None = Field(
        default=None,
        description="æœˆä»½ (æ ¼å¼: 2026-01)ï¼Œé è¨­ç‚ºæœ¬æœˆ",
    )


def _get_reviews_dir() -> Path:
    """Get the reviews directory path."""
    return _data_dir / "reviews"


def _get_week_range(week_str: str) -> tuple[datetime, datetime]:
    """Get start and end dates for a week string (YYYY-Www).

    Args:
        week_str: Week string like '2026-W03'.

    Returns:
        Tuple of (start_date, end_date) as datetime objects.
    """
    # Parse week string
    year = int(week_str[:4])
    week = int(week_str[6:])

    # Get first day of the week (Monday)
    start = datetime.strptime(f"{year}-W{week:02d}-1", "%Y-W%W-%w")
    end = start + __import__("datetime").timedelta(days=6)

    return start, end


def _get_month_range(month_str: str) -> tuple[datetime, datetime]:
    """Get start and end dates for a month string (YYYY-MM).

    Args:
        month_str: Month string like '2026-01'.

    Returns:
        Tuple of (start_date, end_date) as datetime objects.
    """
    import calendar

    year = int(month_str[:4])
    month = int(month_str[5:7])

    start = datetime(year, month, 1)
    _, last_day = calendar.monthrange(year, month)
    end = datetime(year, month, last_day)

    return start, end


async def _collect_completed_tasks_in_range(
    start_date: datetime, end_date: datetime
) -> dict[str, list[dict[str, Any]]]:
    """Collect completed tasks within a date range across all projects.

    Args:
        start_date: Start of the range.
        end_date: End of the range.

    Returns:
        Dictionary mapping project name to list of completed tasks.
    """
    results: dict[str, list[dict[str, Any]]] = {}

    for name, project_path, is_folder in _iter_all_projects():
        if not is_folder:
            continue

        tasks_path = project_path.parent / "tasks.md"
        if not tasks_path.exists():
            continue

        try:
            tasks_content = tasks_path.read_text(encoding="utf-8")
            parsed = _parse_tasks(tasks_content)

            completed_in_range = []
            for task in parsed["completed"]:
                if "completed_date" in task:
                    task_date = datetime.strptime(task["completed_date"], "%Y-%m-%d")
                    if start_date <= task_date <= end_date:
                        completed_in_range.append(task)

            if completed_in_range:
                results[name] = completed_in_range

        except (OSError, IOError) as e:
            logger.warning(f"Failed to read tasks for {name}: {e}")

    return results


async def _collect_git_commits_in_range(
    repo_path: Path, start_date: datetime, end_date: datetime
) -> list[str]:
    """Collect git commits within a date range.

    Args:
        repo_path: Path to the repository.
        start_date: Start of the range.
        end_date: End of the range.

    Returns:
        List of commit lines (hash + message).
    """
    start_str = start_date.strftime("%Y-%m-%d")
    end_str = end_date.strftime("%Y-%m-%d")

    log = await _run_git_command(
        repo_path,
        ["log", f"--since={start_str}", f"--until={end_str}", "--oneline"],
    )

    return log.split("\n") if log else []


async def _generate_reflection_questions(
    completed_tasks: dict[str, list[dict[str, Any]]],
    commits_summary: dict[str, list[str]],
) -> str:
    """Use AI to generate reflection questions based on completed work.

    Args:
        completed_tasks: Completed tasks by project.
        commits_summary: Git commits by project.

    Returns:
        AI-generated reflection questions in Traditional Chinese.
    """
    # Build summary for AI
    summary_parts = []
    for project, tasks in completed_tasks.items():
        task_texts = [t["text"] for t in tasks]
        summary_parts.append(f"**{project}** å®Œæˆä»»å‹™: {', '.join(task_texts)}")

    for project, commits in commits_summary.items():
        if commits:
            summary_parts.append(f"**{project}** commits: {len(commits)} ç­†")

    if not summary_parts:
        return "- æœ¬é€±æ²’æœ‰å®Œæˆçš„ä»»å‹™ï¼Œä¸‹é€±æœ‰ä»€éº¼æƒ³è¦é”æˆçš„ç›®æ¨™ï¼Ÿ"

    prompt = f"""æ ¹æ“šä»¥ä¸‹æœ¬é€±å®Œæˆçš„å·¥ä½œï¼Œç”Ÿæˆ 3-5 å€‹åæ€å•é¡Œã€‚å•é¡Œæ‡‰è©²å¹«åŠ©ä½¿ç”¨è€…ï¼š
1. å›é¡§æœ¬é€±çš„æˆå°±
2. è­˜åˆ¥å­¸ç¿’å’Œæˆé•·
3. æ€è€ƒä¸‹é€±çš„å„ªå…ˆäº‹é …

æœ¬é€±å·¥ä½œæ‘˜è¦ï¼š
{chr(10).join(summary_parts)}

è«‹ç›´æ¥è¼¸å‡ºå•é¡Œï¼Œæ¯å€‹å•é¡Œä¸€è¡Œï¼Œç”¨ "- " é–‹é ­ã€‚ç¹é«”ä¸­æ–‡ã€‚"""

    options = ClaudeAgentOptions(model="claude-haiku-3-5-20241022")
    result_text = ""

    async for message in query(prompt=prompt, options=options):
        if isinstance(message, ResultMessage):
            if hasattr(message, "result") and message.result:
                result_text = message.result
                break

    return result_text or "- æœ¬é€±æœ‰ä»€éº¼è®“ä½ æ„Ÿåˆ°è‡ªè±ªçš„æˆå°±ï¼Ÿ\n- ä¸‹é€±æœ€é‡è¦çš„ä¸€ä»¶äº‹æ˜¯ä»€éº¼ï¼Ÿ"


@tool(
    name="weekly_review",
    description="ç”Ÿæˆé€±å›é¡§å ±å‘Šã€‚çµ±è¨ˆæœ¬é€±å®Œæˆçš„ä»»å‹™ã€git commitsï¼Œä¸¦ç”Ÿæˆ AI åæ€å•é¡Œã€‚è¼¸å‡ºåˆ° data/reviews/weekly/YYYY-Www.mdã€‚",
    input_schema=WeeklyReviewInput.model_json_schema(),
)
async def weekly_review(args: dict[str, Any]) -> dict[str, Any]:
    """Generate weekly review report.

    çµ±è¨ˆæœ¬é€±å®Œæˆçš„ä»»å‹™ã€å„å°ˆæ¡ˆ git commitsï¼Œ
    ä¸¦ä½¿ç”¨ AI ç”Ÿæˆåæ€å•é¡Œã€‚

    Args:
        args: Dictionary containing optional 'week' (format: 2026-W03).

    Returns:
        Tool response with review summary and file path.
    """
    try:
        validated = WeeklyReviewInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    # Determine week
    if validated.week:
        week_str = validated.week
    else:
        today = datetime.now()
        week_str = today.strftime("%Y-W%W")

    # Get week range
    try:
        start_date, end_date = _get_week_range(week_str)
    except ValueError:
        return {
            "content": [
                {"type": "text", "text": f"ç„¡æ•ˆçš„é€±æ¬¡æ ¼å¼ï¼š{week_str}ï¼Œè«‹ä½¿ç”¨ YYYY-Www æ ¼å¼"}
            ],
            "is_error": True,
        }

    # Collect completed tasks
    completed_tasks = await _collect_completed_tasks_in_range(start_date, end_date)

    # Collect git commits for each project
    commits_summary: dict[str, list[str]] = {}
    for name, project_path, is_folder in _iter_all_projects():
        post = frontmatter.load(project_path)
        repo_path_str = post.get("repo", "")
        if repo_path_str:
            repo_path = Path(repo_path_str).expanduser()
            if repo_path.exists():
                commits = await _collect_git_commits_in_range(repo_path, start_date, end_date)
                if commits:
                    commits_summary[name] = commits

    # Generate reflection questions
    reflection = await _generate_reflection_questions(completed_tasks, commits_summary)

    # Build review content
    lines = [
        f"# é€±å›é¡§ {week_str}",
        "",
        f"**æœŸé–“**: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}",
        f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "## å®Œæˆçš„ä»»å‹™",
        "",
    ]

    if completed_tasks:
        for project, tasks in completed_tasks.items():
            lines.append(f"### {project}")
            for task in tasks:
                date_str = task.get("completed_date", "")
                lines.append(f"- [x] {task['text']} ({date_str})")
            lines.append("")
    else:
        lines.append("_æœ¬é€±æ²’æœ‰æ¨™è¨˜å®Œæˆçš„ä»»å‹™_")
        lines.append("")

    lines.append("## Git Commits æ‘˜è¦")
    lines.append("")

    if commits_summary:
        for project, commits in commits_summary.items():
            lines.append(f"### {project} ({len(commits)} commits)")
            for commit in commits[:10]:  # Show first 10
                lines.append(f"- {commit}")
            if len(commits) > 10:
                lines.append(f"- ... å…± {len(commits)} ç­†")
            lines.append("")
    else:
        lines.append("_æœ¬é€±æ²’æœ‰ commits_")
        lines.append("")

    lines.append("## åæ€å•é¡Œ")
    lines.append("")
    lines.append(reflection)
    lines.append("")

    # Save to file
    reviews_dir = _get_reviews_dir() / "weekly"
    reviews_dir.mkdir(parents=True, exist_ok=True)
    review_file = reviews_dir / f"{week_str}.md"
    review_content = "\n".join(lines)
    review_file.write_text(review_content, encoding="utf-8")

    # Summary for response
    total_tasks = sum(len(tasks) for tasks in completed_tasks.values())
    total_commits = sum(len(commits) for commits in commits_summary.values())

    return {
        "content": [
            {
                "type": "text",
                "text": f"""## é€±å›é¡§ {week_str} å·²ç”Ÿæˆ

**çµ±è¨ˆ**:
- å®Œæˆä»»å‹™: {total_tasks} é …
- Git commits: {total_commits} ç­†
- æ¶µè“‹å°ˆæ¡ˆ: {len(completed_tasks) + len(commits_summary)} å€‹

**æª”æ¡ˆ**: `{review_file}`

{reflection}""",
            }
        ],
    }


@tool(
    name="monthly_review",
    description="ç”Ÿæˆæœˆå›é¡§å ±å‘Šã€‚çµ±è¨ˆæœ¬æœˆå°ˆæ¡ˆé€²åº¦ã€æˆå°±æ¸…å–®ã€å­¸ç¿’ç´€éŒ„ã€‚è¼¸å‡ºåˆ° data/reviews/monthly/YYYY-MM.mdã€‚",
    input_schema=MonthlyReviewInput.model_json_schema(),
)
async def monthly_review(args: dict[str, Any]) -> dict[str, Any]:
    """Generate monthly review report.

    çµ±è¨ˆæœ¬æœˆå°ˆæ¡ˆé€²åº¦ç¸½è¦½ã€æœˆåº¦æˆå°±æ¸…å–®ã€å­¸ç¿’èˆ‡æˆé•·ç´€éŒ„ã€‚

    Args:
        args: Dictionary containing optional 'month' (format: 2026-01).

    Returns:
        Tool response with review summary and file path.
    """
    try:
        validated = MonthlyReviewInput(**args)
    except ValueError as e:
        return {
            "content": [{"type": "text", "text": f"è¼¸å…¥é©—è­‰å¤±æ•—ï¼š{e}"}],
            "is_error": True,
        }

    # Determine month
    if validated.month:
        month_str = validated.month
    else:
        today = datetime.now()
        month_str = today.strftime("%Y-%m")

    # Get month range
    try:
        start_date, end_date = _get_month_range(month_str)
    except ValueError:
        return {
            "content": [
                {"type": "text", "text": f"ç„¡æ•ˆçš„æœˆä»½æ ¼å¼ï¼š{month_str}ï¼Œè«‹ä½¿ç”¨ YYYY-MM æ ¼å¼"}
            ],
            "is_error": True,
        }

    # Collect completed tasks
    completed_tasks = await _collect_completed_tasks_in_range(start_date, end_date)

    # Collect project progress
    project_progress: list[dict[str, Any]] = []
    commits_summary: dict[str, list[str]] = {}

    for name, project_path, is_folder in _iter_all_projects():
        post = frontmatter.load(project_path)
        task_counts = _count_tasks(project_path)

        project_info = {
            "name": post.get("name", name),
            "status": post.get("status", "unknown"),
            "progress": post.get("progress", _calculate_progress(project_path)),
            "tasks": task_counts,
        }
        project_progress.append(project_info)

        # Collect git commits
        repo_path_str = post.get("repo", "")
        if repo_path_str:
            repo_path = Path(repo_path_str).expanduser()
            if repo_path.exists():
                commits = await _collect_git_commits_in_range(repo_path, start_date, end_date)
                if commits:
                    commits_summary[name] = commits

    # Build review content
    month_name = start_date.strftime("%Y å¹´ %m æœˆ")
    lines = [
        f"# æœˆå›é¡§ {month_name}",
        "",
        f"**æœŸé–“**: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}",
        f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        "",
        "## å°ˆæ¡ˆé€²åº¦ç¸½è¦½",
        "",
    ]

    for proj in project_progress:
        status_emoji = {
            "active": "ğŸŸ¢",
            "paused": "â¸ï¸",
            "completed": "âœ…",
            "archived": "ğŸ“¦",
        }.get(proj["status"], "â“")

        tasks = proj["tasks"]
        task_str = (
            f"{tasks['completed']}/{tasks['total']} tasks" if tasks["total"] > 0 else "0 tasks"
        )
        commits_count = len(commits_summary.get(proj["name"].lower(), []))
        commits_str = f", {commits_count} commits" if commits_count > 0 else ""

        lines.append(f"- {status_emoji} **{proj['name']}**: {task_str}{commits_str}")

    lines.append("")
    lines.append("## æœˆåº¦æˆå°±æ¸…å–®")
    lines.append("")

    if completed_tasks:
        total_count = 0
        for project, tasks in completed_tasks.items():
            lines.append(f"### {project}")
            for task in tasks:
                lines.append(f"- [x] {task['text']}")
                total_count += 1
            lines.append("")
        lines.append(f"**å…±å®Œæˆ {total_count} é …ä»»å‹™**")
    else:
        lines.append("_æœ¬æœˆæ²’æœ‰æ¨™è¨˜å®Œæˆçš„ä»»å‹™_")

    lines.append("")
    lines.append("## å­¸ç¿’èˆ‡æˆé•·")
    lines.append("")
    lines.append("<!-- æ‰‹å‹•å¡«å¯«æœ¬æœˆå­¸åˆ°çš„æ–°æŠ€è¡“ã€æ¦‚å¿µæˆ–æŠ€èƒ½ -->")
    lines.append("- ")
    lines.append("")
    lines.append("## ä¸‹æœˆç›®æ¨™")
    lines.append("")
    lines.append("<!-- æ‰‹å‹•å¡«å¯«ä¸‹å€‹æœˆæƒ³è¦é”æˆçš„ç›®æ¨™ -->")
    lines.append("- ")
    lines.append("")

    # Save to file
    reviews_dir = _get_reviews_dir() / "monthly"
    reviews_dir.mkdir(parents=True, exist_ok=True)
    review_file = reviews_dir / f"{month_str}.md"
    review_content = "\n".join(lines)
    review_file.write_text(review_content, encoding="utf-8")

    # Summary for response
    total_tasks = sum(len(tasks) for tasks in completed_tasks.values())
    total_commits = sum(len(commits) for commits in commits_summary.values())

    return {
        "content": [
            {
                "type": "text",
                "text": f"""## æœˆå›é¡§ {month_name} å·²ç”Ÿæˆ

**çµ±è¨ˆ**:
- è¿½è¹¤å°ˆæ¡ˆ: {len(project_progress)} å€‹
- å®Œæˆä»»å‹™: {total_tasks} é …
- Git commits: {total_commits} ç­†

**æª”æ¡ˆ**: `{review_file}`

è«‹æª¢æŸ¥ä¸¦æ‰‹å‹•å¡«å¯«ã€Œå­¸ç¿’èˆ‡æˆé•·ã€å’Œã€Œä¸‹æœˆç›®æ¨™ã€å€å¡Šã€‚""",
            }
        ],
    }


# åŒ¯å‡ºæ‰€æœ‰å·¥å…·ï¼Œæ–¹ä¾¿ agent.py ä½¿ç”¨
all_tools = [
    list_projects,
    show_project,
    get_today_tasks,
    sync_project,
    weekly_review,
    monthly_review,
]

# ä¿ç•™ä½†ä¸é è¨­å•Ÿç”¨çš„å·¥å…·ï¼ˆå¯ç”± agent æŒ‰éœ€åŠ å…¥ï¼‰
optional_tools = [
    update_project_status,
    update_project_progress,
]
